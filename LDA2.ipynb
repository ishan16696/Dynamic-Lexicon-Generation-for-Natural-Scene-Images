{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer,SnowballStemmer\n",
    "\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/tyagi/Downloads/Project/annotations_trainval2017/annotations/captions_val2017.json\") as file:\n",
    "    data_val=json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/home/tyagi/Downloads/project_data_bhavin/annotations_trainval2014/annotations/captions_val2014.json\") as file:\n",
    "#     data_val=json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "info 6\n",
      "licenses 8\n",
      "images 5000\n",
      "annotations 25014\n"
     ]
    }
   ],
   "source": [
    "print(len(data_val))\n",
    "#print(data_val[\"annotations\"])\n",
    "for i in data_val.keys():\n",
    "    print(i,len(data_val[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data_val[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'COCO 2017 Dataset', 'url': 'http://cocodataset.org', 'version': '1.0', 'year': 2017, 'contributor': 'COCO Consortium', 'date_created': '2017/09/01'}\n"
     ]
    }
   ],
   "source": [
    "print(data_val[\"info\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25014\n",
      "{'image_id': 245764, 'id': 370033, 'caption': 'A cat sitting on the edge of the toilet looking toward the open bathroom door.'}\n"
     ]
    }
   ],
   "source": [
    "print(len(data_val['annotations']))\n",
    "print(data_val['annotations'][1804])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n",
      "A cat sits on the edge of a toilet.\n",
      "1804\n",
      "A cat sitting on the edge of the toilet looking toward the open bathroom door.\n",
      "1813\n",
      "a black and gray cat is sitting on a toilet\n",
      "1814\n",
      "A cat laying on a toilet seat with its paws inside .\n",
      "1830\n",
      "A cat is laying on a toilet seat\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for images in data_val['annotations']:\n",
    "    count +=1\n",
    "    if images['image_id'] == 245764:\n",
    "        print(count-1)\n",
    "        print(images['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    #return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def preprocess(text):\n",
    "    #print(text)\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(lemmatize_stemming(token)) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edge', 'toilet']\n",
      "['edge', 'toilet', 'look', 'open', 'bathroom', 'door']\n",
      "['black', 'gray', 'toilet']\n",
      "['toilet', 'seat', 'inside']\n",
      "['toilet', 'seat']\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for images in data_val['annotations']:\n",
    "    if images['image_id'] == 245764:\n",
    "        result=preprocess(images['caption'])\n",
    "        #count+=1\n",
    "        print(result)\n",
    "        \n",
    "#print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_set = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict={}\n",
    "for image in data_val['annotations']:\n",
    "    if image[\"image_id\"] in data_dict:\n",
    "        data_dict[image[\"image_id\"]].append(image[\"caption\"])\n",
    "    else:\n",
    "        data_dict.update({image[\"image_id\"]:[image[\"caption\"]]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(data_dict)) ### image_id(key) -- > text_corpus(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A cat sits on the edge of a toilet.', 'A cat sitting on the edge of the toilet looking toward the open bathroom door.', 'a black and gray cat is sitting on a toilet', 'A cat laying on a toilet seat with its paws inside .', 'A cat is laying on a toilet seat']\n"
     ]
    }
   ],
   "source": [
    "print(data_dict[245764])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data_dict.items(),columns=['image_id','text_corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two women waiting at a bench next to a street.',\n",
       " 'A woman sitting on a bench and a woman standing waiting for the bus.',\n",
       " 'A woman sitting on a bench in the middle of the city',\n",
       " 'A woman sitting on a bench and a woman standing behind the bench at a bus stop',\n",
       " 'A woman and another woman waiting at a stop.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3]['text_corpus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>text_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179765</td>\n",
       "      <td>[A black Honda motorcycle parked in front of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190236</td>\n",
       "      <td>[An office cubicle with four different types o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>331352</td>\n",
       "      <td>[A small closed toilet in a cramped space., A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>517069</td>\n",
       "      <td>[Two women waiting at a bench next to a street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182417</td>\n",
       "      <td>[A beautiful dessert waiting to be shared by t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                        text_corpus\n",
       "0    179765  [A black Honda motorcycle parked in front of a...\n",
       "1    190236  [An office cubicle with four different types o...\n",
       "2    331352  [A small closed toilet in a cramped space., A ...\n",
       "3    517069  [Two women waiting at a bench next to a street...\n",
       "4    182417  [A beautiful dessert waiting to be shared by t..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemm(text):\n",
    "    #return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def preprocessing(Bigtext):\n",
    "    \n",
    "    result = []\n",
    "    for text in Bigtext:\n",
    "        for token in gensim.utils.simple_preprocess(text):\n",
    "            if token not in gensim.parsing.preprocessing.STOPWORDS and len(lemmatize_stemm(token)) > 3:\n",
    "                #print(token)\n",
    "                result.append(lemmatize_stemm(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_gensim={}\n",
    "for i in range(df.shape[0]):\n",
    "    dict_gensim.update({i:preprocessing(df.iloc[i][\"text_corpus\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black', 'honda', 'motorcycle', 'park', 'garage', 'honda', 'motorcycle', 'park', 'grass', 'driveway', 'black', 'honda', 'motorcycle', 'dark', 'burgundy', 'seat', 'motorcycle', 'park', 'gravel', 'garage', 'motorcycle', 'brake', 'extend', 'stand', 'outside']\n"
     ]
    }
   ],
   "source": [
    "print(dict_gensim[0])\n",
    "dd=pd.Series(dict_gensim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "(5000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [black, honda, motorcycle, park, garage, honda...\n",
       "1    [office, cubicle, different, type, computers, ...\n",
       "2    [small, close, toilet, cramp, space, toilet, s...\n",
       "3    [women, wait, bench, street, woman, bench, wom...\n",
       "4    [beautiful, dessert, wait, share, people, piec...\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(dd))\n",
    "print(dd.shape)\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(dd)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(4994 unique tokens: ['black', 'brake', 'burgundy', 'dark', 'driveway']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 black\n",
      "1 brake\n",
      "2 burgundy\n",
      "3 dark\n",
      "4 driveway\n",
      "5 extend\n",
      "6 garage\n",
      "7 grass\n",
      "8 gravel\n",
      "9 honda\n",
      "10 motorcycle\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4994"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in dd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 15 (\"chair\") appears 2 time.\n",
      "Word 16 (\"clutter\") appears 1 time.\n",
      "Word 17 (\"computers\") appears 1 time.\n",
      "Word 18 (\"cubicle\") appears 2 time.\n",
      "Word 19 (\"desk\") appears 2 time.\n",
      "Word 20 (\"different\") appears 1 time.\n",
      "Word 21 (\"home\") appears 1 time.\n",
      "Word 22 (\"laptop\") appears 1 time.\n",
      "Word 23 (\"office\") appears 5 time.\n",
      "Word 24 (\"screen\") appears 1 time.\n",
      "Word 25 (\"space\") appears 1 time.\n",
      "Word 26 (\"type\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_1 = bow_corpus[1]\n",
    "\n",
    "for i in range(len(bow_doc_1)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_1[i][0],dictionary[bow_doc_1[i][0]], bow_doc_1[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=30, id2word=dictionary, passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=20, id2word=dictionary, passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.142*\"play\" + 0.087*\"game\" + 0.048*\"children\" + 0.044*\"video\" + 0.042*\"young\" + 0.028*\"remote\" + 0.028*\"hold\" + 0.027*\"sleep\" + 0.027*\"blanket\" + 0.019*\"girls\"\n",
      "Topic: 1 \n",
      "Words: 0.097*\"bottle\" + 0.071*\"plant\" + 0.069*\"water\" + 0.059*\"drink\" + 0.045*\"reach\" + 0.042*\"bridge\" + 0.031*\"feed\" + 0.030*\"milk\" + 0.022*\"baby\" + 0.020*\"leave\"\n",
      "Topic: 2 \n",
      "Words: 0.118*\"bird\" + 0.059*\"airplane\" + 0.054*\"plane\" + 0.042*\"large\" + 0.036*\"rock\" + 0.030*\"blue\" + 0.027*\"runway\" + 0.024*\"white\" + 0.024*\"small\" + 0.022*\"airport\"\n",
      "Topic: 3 \n",
      "Words: 0.100*\"stand\" + 0.084*\"field\" + 0.072*\"tree\" + 0.067*\"grass\" + 0.036*\"giraffe\" + 0.035*\"fence\" + 0.028*\"giraffes\" + 0.028*\"zebra\" + 0.028*\"zebras\" + 0.027*\"green\"\n",
      "Topic: 4 \n",
      "Words: 0.168*\"laptop\" + 0.133*\"desk\" + 0.095*\"elephant\" + 0.055*\"keyboard\" + 0.049*\"monitor\" + 0.033*\"mouse\" + 0.025*\"office\" + 0.024*\"computers\" + 0.023*\"screen\" + 0.020*\"table\"\n",
      "Topic: 5 \n",
      "Words: 0.210*\"cake\" + 0.032*\"candle\" + 0.028*\"birthday\" + 0.024*\"pink\" + 0.024*\"chocolate\" + 0.021*\"frost\" + 0.021*\"table\" + 0.020*\"apple\" + 0.018*\"doughnut\" + 0.016*\"donut\"\n",
      "Topic: 6 \n",
      "Words: 0.126*\"plate\" + 0.047*\"food\" + 0.038*\"sandwich\" + 0.034*\"slice\" + 0.032*\"white\" + 0.026*\"broccoli\" + 0.025*\"table\" + 0.023*\"vegetables\" + 0.022*\"piece\" + 0.021*\"banana\"\n",
      "Topic: 7 \n",
      "Words: 0.135*\"skateboard\" + 0.090*\"person\" + 0.063*\"board\" + 0.055*\"trick\" + 0.053*\"jump\" + 0.049*\"skate\" + 0.031*\"skateboarder\" + 0.031*\"young\" + 0.030*\"ramp\" + 0.017*\"perform\"\n",
      "Topic: 8 \n",
      "Words: 0.113*\"snow\" + 0.042*\"snowy\" + 0.042*\"mountain\" + 0.041*\"cover\" + 0.040*\"slope\" + 0.040*\"hill\" + 0.037*\"person\" + 0.036*\"bananas\" + 0.033*\"fruit\" + 0.032*\"stand\"\n",
      "Topic: 9 \n",
      "Words: 0.181*\"phone\" + 0.096*\"cell\" + 0.054*\"take\" + 0.044*\"picture\" + 0.033*\"talk\" + 0.025*\"hold\" + 0.022*\"cellphone\" + 0.020*\"hang\" + 0.018*\"bunch\" + 0.017*\"bananas\"\n",
      "Topic: 10 \n",
      "Words: 0.220*\"walk\" + 0.070*\"sheep\" + 0.056*\"elephants\" + 0.034*\"stand\" + 0.034*\"road\" + 0.030*\"herd\" + 0.021*\"cross\" + 0.016*\"group\" + 0.015*\"animals\" + 0.014*\"dirt\"\n",
      "Topic: 11 \n",
      "Words: 0.098*\"flower\" + 0.092*\"bike\" + 0.077*\"vase\" + 0.063*\"bicycle\" + 0.029*\"paint\" + 0.020*\"purple\" + 0.019*\"shape\" + 0.016*\"white\" + 0.014*\"fill\" + 0.013*\"decorate\"\n",
      "Topic: 12 \n",
      "Words: 0.335*\"people\" + 0.152*\"group\" + 0.070*\"stand\" + 0.030*\"women\" + 0.027*\"couple\" + 0.022*\"crowd\" + 0.017*\"umbrellas\" + 0.015*\"gather\" + 0.015*\"large\" + 0.013*\"picture\"\n",
      "Topic: 13 \n",
      "Words: 0.168*\"table\" + 0.112*\"pizza\" + 0.056*\"food\" + 0.042*\"glass\" + 0.024*\"wine\" + 0.024*\"display\" + 0.022*\"plat\" + 0.019*\"restaurant\" + 0.017*\"drink\" + 0.016*\"wooden\"\n",
      "Topic: 14 \n",
      "Words: 0.119*\"bathroom\" + 0.093*\"toilet\" + 0.062*\"sink\" + 0.044*\"white\" + 0.044*\"mirror\" + 0.023*\"small\" + 0.020*\"wall\" + 0.020*\"shower\" + 0.015*\"tile\" + 0.014*\"seat\"\n",
      "Topic: 15 \n",
      "Words: 0.147*\"bear\" + 0.086*\"wave\" + 0.085*\"surfboard\" + 0.067*\"teddy\" + 0.055*\"surf\" + 0.049*\"stuff\" + 0.038*\"board\" + 0.035*\"ocean\" + 0.029*\"surfer\" + 0.024*\"water\"\n",
      "Topic: 16 \n",
      "Words: 0.232*\"tennis\" + 0.101*\"motorcycle\" + 0.076*\"court\" + 0.064*\"ball\" + 0.054*\"racket\" + 0.050*\"player\" + 0.039*\"play\" + 0.027*\"racquet\" + 0.022*\"swing\" + 0.018*\"hold\"\n",
      "Topic: 17 \n",
      "Words: 0.128*\"frisbee\" + 0.070*\"luggage\" + 0.055*\"book\" + 0.033*\"play\" + 0.032*\"suitcase\" + 0.032*\"throw\" + 0.031*\"catch\" + 0.024*\"stack\" + 0.017*\"suitcases\" + 0.015*\"field\"\n",
      "Topic: 18 \n",
      "Words: 0.128*\"water\" + 0.124*\"beach\" + 0.089*\"boat\" + 0.064*\"kite\" + 0.029*\"near\" + 0.025*\"river\" + 0.024*\"ocean\" + 0.021*\"stand\" + 0.021*\"body\" + 0.021*\"sand\"\n",
      "Topic: 19 \n",
      "Words: 0.133*\"horse\" + 0.104*\"bench\" + 0.084*\"black\" + 0.075*\"white\" + 0.045*\"window\" + 0.038*\"look\" + 0.034*\"brown\" + 0.033*\"wooden\" + 0.027*\"orange\" + 0.024*\"pair\"\n",
      "Topic: 20 \n",
      "Words: 0.170*\"kitchen\" + 0.048*\"refrigerator\" + 0.043*\"counter\" + 0.043*\"oven\" + 0.037*\"stave\" + 0.024*\"white\" + 0.024*\"cabinets\" + 0.023*\"microwave\" + 0.020*\"sink\" + 0.020*\"cook\"\n",
      "Topic: 21 \n",
      "Words: 0.160*\"bowl\" + 0.040*\"oranges\" + 0.037*\"apples\" + 0.025*\"school\" + 0.020*\"fill\" + 0.016*\"table\" + 0.015*\"bean\" + 0.014*\"white\" + 0.013*\"green\" + 0.012*\"spoon\"\n",
      "Topic: 22 \n",
      "Words: 0.180*\"baseball\" + 0.059*\"player\" + 0.050*\"game\" + 0.045*\"ball\" + 0.045*\"field\" + 0.033*\"swing\" + 0.029*\"players\" + 0.022*\"batter\" + 0.019*\"play\" + 0.018*\"hold\"\n",
      "Topic: 23 \n",
      "Words: 0.091*\"soccer\" + 0.065*\"pull\" + 0.052*\"ball\" + 0.042*\"stick\" + 0.034*\"cart\" + 0.030*\"carriage\" + 0.028*\"field\" + 0.025*\"draw\" + 0.024*\"kick\" + 0.022*\"play\"\n",
      "Topic: 24 \n",
      "Words: 0.119*\"clock\" + 0.108*\"build\" + 0.055*\"tower\" + 0.048*\"large\" + 0.038*\"wall\" + 0.024*\"tall\" + 0.023*\"brick\" + 0.018*\"statue\" + 0.014*\"white\" + 0.010*\"hang\"\n",
      "Topic: 25 \n",
      "Words: 0.184*\"park\" + 0.064*\"truck\" + 0.049*\"hydrant\" + 0.029*\"street\" + 0.024*\"road\" + 0.023*\"build\" + 0.022*\"sidewalk\" + 0.022*\"white\" + 0.021*\"yellow\" + 0.020*\"near\"\n",
      "Topic: 26 \n",
      "Words: 0.137*\"room\" + 0.080*\"chair\" + 0.065*\"live\" + 0.044*\"couch\" + 0.037*\"table\" + 0.026*\"floor\" + 0.022*\"television\" + 0.019*\"large\" + 0.017*\"bedroom\" + 0.014*\"furniture\"\n",
      "Topic: 27 \n",
      "Words: 0.164*\"street\" + 0.114*\"sign\" + 0.055*\"city\" + 0.049*\"light\" + 0.044*\"stop\" + 0.033*\"road\" + 0.031*\"traffic\" + 0.029*\"build\" + 0.023*\"cars\" + 0.020*\"pole\"\n",
      "Topic: 28 \n",
      "Words: 0.229*\"train\" + 0.089*\"track\" + 0.047*\"station\" + 0.029*\"travel\" + 0.027*\"yellow\" + 0.015*\"passenger\" + 0.014*\"tree\" + 0.014*\"branch\" + 0.013*\"white\" + 0.013*\"platform\"\n",
      "Topic: 29 \n",
      "Words: 0.169*\"woman\" + 0.106*\"hold\" + 0.053*\"stand\" + 0.045*\"girl\" + 0.042*\"umbrella\" + 0.041*\"person\" + 0.039*\"young\" + 0.038*\"wear\" + 0.026*\"hand\" + 0.025*\"child\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda_model.get_topic_terms(0,topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(lda_model.print_topics(num_topics=10,num_words=30)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0.28261536), (8, 0.096668996), (15, 0.587378)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model[bow_corpus[4999]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "noofTopics=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict={}\n",
    "for j in range(len(bow_corpus)):\n",
    "    li=[0.0]*noofTopics  ### len == no of topics\n",
    "    probDist=lda_model[bow_corpus[j]]\n",
    "    for i in range(len(probDist)):\n",
    "        li[probDist[i][0]]=probDist[i][1]\n",
    "    final_dict[df.iloc[j][\"image_id\"]]=li\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_dict[397133]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.055744477,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5736014,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.32779655]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict[139]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.31480938,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.22091118,\n",
       " 0.0,\n",
       " 0.4332334]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict[1296]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedWriter.close>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "f=open(\"ldaResult\",\"wb\") \n",
    "pickle.dump(final_dict,f)\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"Dict\",\"wb\") as f:\n",
    "    pickle.dump(dictionary,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word_prob={}\n",
    "for i in range(noofTopics):\n",
    "    word_prob={}\n",
    "    ss=lda_model.get_topic_terms(i,topn=100)\n",
    "    for x in ss:\n",
    "        word_prob[dictionary[x[0]]]=x[1]\n",
    "    topic_word_prob[i]=word_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"topic_word_prob\",\"wb\") as f:\n",
    "    pickle.dump(topic_word_prob,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.037*\"baseball\" + 0.035*\"horse\" + 0.021*\"bench\" + 0.012*\"game\" + 0.011*\"player\" + 0.010*\"girl\" + 0.010*\"woman\" + 0.010*\"phone\" + 0.010*\"hold\" + 0.010*\"ball\"\n",
      "\n",
      "Topic: 1 Word: 0.035*\"sign\" + 0.030*\"street\" + 0.022*\"wave\" + 0.021*\"surfboard\" + 0.018*\"bird\" + 0.016*\"stop\" + 0.014*\"light\" + 0.014*\"surf\" + 0.012*\"traffic\" + 0.011*\"city\"\n",
      "\n",
      "Topic: 2 Word: 0.041*\"tennis\" + 0.037*\"train\" + 0.024*\"clock\" + 0.023*\"motorcycle\" + 0.015*\"track\" + 0.014*\"court\" + 0.014*\"build\" + 0.012*\"tower\" + 0.012*\"park\" + 0.012*\"street\"\n",
      "\n",
      "Topic: 3 Word: 0.042*\"hydrant\" + 0.031*\"phone\" + 0.020*\"soccer\" + 0.019*\"cell\" + 0.011*\"talk\" + 0.006*\"bean\" + 0.006*\"kick\" + 0.005*\"cellphone\" + 0.004*\"smart\" + 0.003*\"sidewalk\"\n",
      "\n",
      "Topic: 4 Word: 0.018*\"bear\" + 0.018*\"field\" + 0.018*\"stand\" + 0.017*\"snow\" + 0.014*\"grass\" + 0.013*\"frisbee\" + 0.012*\"giraffe\" + 0.011*\"tree\" + 0.011*\"elephant\" + 0.010*\"sheep\"\n",
      "\n",
      "Topic: 5 Word: 0.044*\"skateboard\" + 0.019*\"trick\" + 0.019*\"airplane\" + 0.018*\"plane\" + 0.017*\"skate\" + 0.012*\"jump\" + 0.012*\"skateboarder\" + 0.012*\"ramp\" + 0.012*\"board\" + 0.010*\"runway\"\n",
      "\n",
      "Topic: 6 Word: 0.033*\"plate\" + 0.032*\"pizza\" + 0.025*\"food\" + 0.023*\"table\" + 0.015*\"bowl\" + 0.014*\"sandwich\" + 0.011*\"slice\" + 0.009*\"broccoli\" + 0.009*\"cake\" + 0.009*\"bananas\"\n",
      "\n",
      "Topic: 7 Word: 0.021*\"bathroom\" + 0.021*\"room\" + 0.018*\"toilet\" + 0.016*\"umbrella\" + 0.013*\"live\" + 0.012*\"sink\" + 0.012*\"chair\" + 0.012*\"table\" + 0.011*\"giraffes\" + 0.011*\"people\"\n",
      "\n",
      "Topic: 8 Word: 0.035*\"laptop\" + 0.032*\"beach\" + 0.030*\"boat\" + 0.027*\"desk\" + 0.026*\"kite\" + 0.023*\"truck\" + 0.018*\"water\" + 0.015*\"keyboard\" + 0.013*\"monitor\" + 0.011*\"people\"\n",
      "\n",
      "Topic: 9 Word: 0.051*\"kitchen\" + 0.022*\"refrigerator\" + 0.016*\"oven\" + 0.015*\"stave\" + 0.011*\"cabinets\" + 0.011*\"microwave\" + 0.010*\"counter\" + 0.009*\"scissor\" + 0.009*\"appliances\" + 0.008*\"fridge\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_word_prob={}\n",
    "for i in range(noofTopics):\n",
    "    word_prob={}\n",
    "    ss=lda_model.get_topic_terms(i,topn=100)\n",
    "    for x in ss:\n",
    "        word_prob[dictionary[x[0]]]=x[1]\n",
    "    tf_idf_word_prob[i]=word_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"tf_idf_word_prob\",\"wb\") as f:\n",
    "    pickle.dump(tf_idf_word_prob,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play 0.14164089 play 0.14164089\n",
      "\n",
      "game 0.08689297 game 0.08689297\n",
      "\n",
      "children 0.048346743 children 0.048346743\n",
      "\n",
      "video 0.04423017 video 0.04423017\n",
      "\n",
      "young 0.041784693 young 0.041784693\n",
      "\n",
      "remote 0.028066792 remote 0.028066792\n",
      "\n",
      "hold 0.027923357 hold 0.027923357\n",
      "\n",
      "sleep 0.027151614 sleep 0.027151614\n",
      "\n",
      "blanket 0.026827376 blanket 0.026827376\n",
      "\n",
      "girls 0.019166801 girls 0.019166801\n",
      "\n",
      "controller 0.017698048 controller 0.017698048\n",
      "\n",
      "control 0.016172653 control 0.016172653\n",
      "\n",
      "nintendo 0.014648417 nintendo 0.014648417\n",
      "\n",
      "room 0.01426607 room 0.01426607\n",
      "\n",
      "stand 0.014075527 stand 0.014075527\n",
      "\n",
      "boys 0.013492899 boys 0.013492899\n",
      "\n",
      "little 0.011925609 little 0.011925609\n",
      "\n",
      "controllers 0.011293759 controllers 0.011293759\n",
      "\n",
      "couple 0.011069818 couple 0.011069818\n",
      "\n",
      "small 0.00811082 small 0.00811082\n",
      "\n",
      "remotes 0.0076341354 remotes 0.0076341354\n",
      "\n",
      "screen 0.007387438 screen 0.007387438\n",
      "\n",
      "child 0.0068025882 child 0.0068025882\n",
      "\n",
      "women 0.006658541 women 0.006658541\n",
      "\n",
      "live 0.0066286745 live 0.0066286745\n",
      "\n",
      "couch 0.006433349 couch 0.006433349\n",
      "\n",
      "pillow 0.0061479695 pillow 0.0061479695\n",
      "\n",
      "look 0.005830091 look 0.005830091\n",
      "\n",
      "hand 0.0056848284 hand 0.0056848284\n",
      "\n",
      "curl 0.0054119295 curl 0.0054119295\n",
      "\n",
      "person 0.005393209 person 0.005393209\n",
      "\n",
      "asleep 0.0051941667 asleep 0.0051941667\n",
      "\n",
      "calf 0.005193453 calf 0.005193453\n",
      "\n",
      "face 0.004850717 face 0.004850717\n",
      "\n",
      "kitten 0.004827552 kitten 0.004827552\n",
      "\n",
      "television 0.0048216707 television 0.0048216707\n",
      "\n",
      "head 0.0048135878 head 0.0048135878\n",
      "\n",
      "green 0.004287585 green 0.004287585\n",
      "\n",
      "pour 0.004212646 pour 0.004212646\n",
      "\n",
      "image 0.004174364 image 0.004174364\n",
      "\n",
      "cover 0.0040302407 cover 0.0040302407\n",
      "\n",
      "device 0.003992171 device 0.003992171\n",
      "\n",
      "mother 0.003797188 mother 0.003797188\n",
      "\n",
      "picture 0.003711841 picture 0.003711841\n",
      "\n",
      "homemade 0.0036677893 homemade 0.0036677893\n",
      "\n",
      "interactive 0.00336461 interactive 0.00336461\n",
      "\n",
      "photo 0.003349663 photo 0.003349663\n",
      "\n",
      "enjoy 0.0033344456 enjoy 0.0033344456\n",
      "\n",
      "shoe 0.0032715437 shoe 0.0032715437\n",
      "\n",
      "headphones 0.0030586985 headphones 0.0030586985\n",
      "\n",
      "sheet 0.0030262228 sheet 0.0030262228\n",
      "\n",
      "unmake 0.002754333 unmake 0.002754333\n",
      "\n",
      "shirt 0.0025778743 shirt 0.0025778743\n",
      "\n",
      "nearby 0.0025029592 nearby 0.0025029592\n",
      "\n",
      "football 0.0024494382 football 0.0024494382\n",
      "\n",
      "bedspread 0.0024491854 bedspread 0.0024491854\n",
      "\n",
      "friend 0.0024485954 friend 0.0024485954\n",
      "\n",
      "flat 0.0024429245 flat 0.0024429245\n",
      "\n",
      "close 0.002386643 close 0.002386643\n",
      "\n",
      "watch 0.0023720306 watch 0.0023720306\n",
      "\n",
      "electronic 0.0022860547 electronic 0.0022860547\n",
      "\n",
      "have 0.0022637013 have 0.0022637013\n",
      "\n",
      "friends 0.0022193578 friends 0.0022193578\n",
      "\n",
      "wear 0.002206198 wear 0.002206198\n",
      "\n",
      "grind 0.0021839237 grind 0.0021839237\n",
      "\n",
      "crackers 0.0021442662 crackers 0.0021442662\n",
      "\n",
      "sneakers 0.0021440336 sneakers 0.0021440336\n",
      "\n",
      "toothbrushes 0.0021438308 toothbrushes 0.0021438308\n",
      "\n",
      "celebrate 0.0021434517 celebrate 0.0021434517\n",
      "\n",
      "happily 0.0021430089 happily 0.0021430089\n",
      "\n",
      "parent 0.0021036377 parent 0.0021036377\n",
      "\n",
      "white 0.002059729 white 0.002059729\n",
      "\n",
      "cute 0.0020125841 cute 0.0020125841\n",
      "\n",
      "background 0.0020076232 background 0.0020076232\n",
      "\n",
      "closeup 0.0019088684 closeup 0.0019088684\n",
      "\n",
      "console 0.0018397804 console 0.0018397804\n",
      "\n",
      "monkey 0.0018390166 monkey 0.0018390166\n",
      "\n",
      "button 0.0018188576 button 0.0018188576\n",
      "\n",
      "adults 0.0017938331 adults 0.0017938331\n",
      "\n",
      "baby 0.001653277 baby 0.001653277\n",
      "\n",
      "pair 0.0016495481 pair 0.0016495481\n",
      "\n",
      "brown 0.001647989 brown 0.001647989\n",
      "\n",
      "make 0.0016055924 make 0.0016055924\n",
      "\n",
      "blurry 0.0015926511 blurry 0.0015926511\n",
      "\n",
      "party 0.0015570683 party 0.0015570683\n",
      "\n",
      "bikinis 0.0015339238 bikinis 0.0015339238\n",
      "\n",
      "sailboat 0.0015333031 sailboat 0.0015333031\n",
      "\n",
      "surround 0.0015166851 surround 0.0015166851\n",
      "\n",
      "cereal 0.0015090993 cereal 0.0015090993\n",
      "\n",
      "spread 0.0015001486 spread 0.0015001486\n",
      "\n",
      "male 0.0014540076 male 0.0014540076\n",
      "\n",
      "indoor 0.001338192 indoor 0.001338192\n",
      "\n",
      "orange 0.0013262563 orange 0.0013262563\n",
      "\n",
      "inside 0.0013021779 inside 0.0013021779\n",
      "\n",
      "smile 0.0012402582 smile 0.0012402582\n",
      "\n",
      "girl 0.0012378412 girl 0.0012378412\n",
      "\n",
      "youth 0.0012296503 youth 0.0012296503\n",
      "\n",
      "mustache 0.0012286756 mustache 0.0012286756\n",
      "\n",
      "attentively 0.0012284333 attentively 0.0012284333\n",
      "\n",
      "shark 0.0012281182 shark 0.0012281182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(topic_word_prob[0].keys(),tf_idf_word_prob[0].keys()):\n",
    "    print(x,topic_word_prob[0][x],y,tf_idf_word_prob[0][y])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
